{
  "createdAt": "2025-09-01T13:14:53.645Z",
  "updatedAt": "2025-10-16T08:41:38.751Z",
  "id": "bhBscYglbFhVyIcL",
  "name": "Check minuses API tool",
  "active": false,
  "isArchived": false,
  "nodes": [
    {
      "parameters": {
        "jsCode": "// === Code: normalize_and_ngrams ===\n// INPUT:  HTTP Webhook body { phrase: string, threshold?: number }\n// OUTPUT: { threshold: number, candidates: string[], tokens: string[] }\n// PURPOSE:\n//   1) Normalize the phrase (lowercase, keep letters/digits/underscore and - + #)\n//   2) Remove Russian prepositions as separate words (not touching - + #)\n//   3) Tokenize and build 1..3-gram unique candidates preserving order\n//   4) Provide threshold (default 0.88) downstream\n\n// Input JSON: { company_name, text, threshold? }\nconst body = $json;\nconst prepositions = [\n  \"в\",\"без\",\"до\",\"из\",\"к\",\"и\",\"на\",\"по\",\"о\",\"от\",\"перед\",\"при\",\n  \"через\",\"с\",\"у\",\"за\",\"над\",\"об\",\"под\",\"про\",\"для\",\"между\"\n];\n\n// Нормализуем регистр\nlet text = String(body.args.phrase ?? \"\").toLowerCase();\n\n// Экранируем спецсимволы\nconst escape = s => s.replace(/[.*+?^${}()|[\\]\\\\]/g, \"\\\\$&\");\nconst alts = prepositions.map(escape).join(\"|\");\n\n// Разрешаем буквы, цифры, подчёркивание, а также - + #\nconst re = new RegExp(\n  `(^|[^\\\\p{L}\\\\p{N}_\\\\-+#])(?:${alts})(?=$|[^\\\\p{L}\\\\p{N}_\\\\-+#])`,\n  \"giu\"\n);\n\n// Удаляем предлоги, сохраняя левый разделитель\ntext = text.replace(re, \"$1\");\n\n// Чистим пробелы\ntext = text.replace(/\\s+/g, \" \").trim();\n//const company = body.company_name;\nconst threshold = Math.min(Math.max(\n  Number(String(body?.args?.threshold ?? 0.88).replace(',', '.').trim()) || 0.88\n, 0), 1);\n\nconst tokens = (text.match(/[A-Za-zА-Яа-яЁё0-9][A-Za-zА-Яа-яЁё0-9&.\\-]{0,}/g) || [])\n  .map(s => s.trim())\n  .filter(Boolean);\n\nconst MAX_N = 3;\nconst set = new Set();\nfor (let i = 0; i < tokens.length; i++) {\n  for (let n = 1; n <= MAX_N && i + n <= tokens.length; n++) {\n    const phrase = tokens.slice(i, i+n).join(' ');\n    set.add(phrase);\n  }\n}\nlet candidates = Array.from(set);\n// если пусто — добавляем пустую строку\nif (candidates.length === 0) {\n  candidates = [\"\"];\n}\n\nreturn [{ json: { threshold, candidates,MAX_N } }];\n"
      },
      "id": "c90f42d4-63de-4ef3-8b9e-ca771d252db1",
      "name": "Code: normalize_and_ngrams",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        832,
        288
      ],
      "notes": "Normalize phrase, strip Russian prepositions (keeping - + #), tokenize, and produce 1..3-grams."
    },
    {
      "parameters": {
        "jsCode": "// === Code: explode_candidates ===\n// INPUT:  { threshold, candidates[] }\n// OUTPUT: array of items: { candidate, threshold }\n// PURPOSE: fan-out each n-gram into its own item for embedding + DB lookup\n\nconst { threshold, candidates } = $json;\n\nreturn candidates.map(c => ({ json: { candidate: c, threshold } }));"
      },
      "id": "100c10a3-daca-4f91-b7ba-8b47f4a15e56",
      "name": "Code: explode_candidates",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1072,
        288
      ],
      "notes": "Explode the array of n-gram candidates into one item per candidate."
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.openai.com/v1/embeddings",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "openAiApi",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"model\": \"text-embedding-3-small\",\n  \"input\": \"{{$json.candidate}}\"\n}",
        "options": {
          "redirect": {
            "redirect": {}
          },
          "timeout": 30000
        }
      },
      "id": "25f9a2f9-6661-434a-a5c8-02eff59a6e4d",
      "name": "HTTP: OpenAI Embeddings",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4,
      "position": [
        1312,
        288
      ],
      "retryOnFail": true,
      "waitBetweenTries": 5000,
      "credentials": {
        "openAiApi": {
          "id": "m4NScyhZzV3hBcTr",
          "name": "OpenAi Yads"
        }
      },
      "notes": "Creates an embedding for each candidate n-gram.\n- Set your OpenAI credential on this node.\n- Batch mode is possible later; this keeps it simple and explicit."
    },
    {
      "parameters": {
        "jsCode": "// === Code: build_vector_literal ===\n// INPUT:  HTTP response(s) from OpenAI embeddings (one per candidate)\n// OUTPUT: items: { vector: \"[float,...]\", idx, candidate, threshold }\n// PURPOSE: Convert embedding array into a Postgres vector literal string and\n//          carry candidate + threshold forward for alignment\n\nconst sourceAll = $('Code: explode_candidates').all();\n\nconst out = $input.all().map((r, i) => {\n  // OpenAI HTTP node may put data in r.json.body.data or r.json.data depending on version\n  const emb = r.json?.body?.data?.[0]?.embedding ?? r.json?.data?.[0]?.embedding;\n  if (!Array.isArray(emb) || emb.length === 0) {\n    throw new Error('Embedding not found for item #' + i);\n  }\n  const vector = '[' + emb.map(Number).join(',') + ']';\n  const candidate = sourceAll[i]?.json?.candidate;\n  const threshold = sourceAll[i]?.json?.threshold;\n  return { json: { vector, idx: i, candidate, threshold,company_id:$('When Executed by Another Workflow').first().json.args.company_id } };\n});\n\nreturn out;"
      },
      "id": "ea6ec92e-dbe4-4ebb-a172-a321c4c79e9a",
      "name": "Code: build_vector_literal",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1568,
        288
      ],
      "notes": "Convert embedding arrays into a pgvector literal (e.g., \"[0.1,0.2,...]\")."
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "SELECT v.phrase,  0 - (v.phrase_embedding <#> $1::vector) AS similarity FROM company_content v where company_id=$2\n  ORDER BY v.phrase_embedding <#> $1::vector LIMIT 1;",
        "options": {
          "queryReplacement": "={{$json.vector}},{{$json.company_id}}"
        }
      },
      "id": "ee4f5ecf-faf7-4745-9793-2cbeee5ca66e",
      "name": "Postgres: vector search",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2,
      "position": [
        1840,
        288
      ],
      "credentials": {
        "postgres": {
          "id": "4YkdFJcdTgzo9hkz",
          "name": "PGvector"
        }
      },
      "notes": "Looks up the nearest content phrase using pgvector (<#> = cosine distance if normalized). \n- Assumes table company_content(phrase text, phrase_embedding vector).\n- Returns top-1 match with similarity = -distance."
    },
    {
      "parameters": {
        "jsCode": "// === Code: threshold_flag ===\n// INPUT:  Postgres results (top-1 row per candidate)\n// OUTPUT: items: { candidate, matched, similarity, pass }\n// PURPOSE: Compare best similarity to threshold and flag whether it passes\n\nconst ctx = $('Code: normalize_and_ngrams').first().json; // { threshold, candidates, tokens }\nconst exploded = $('Code: explode_candidates').all();\n\nconst out = $input.all().map((row, i) => {\n  const best = row.json || {};\n  const candidate = exploded[i]?.json?.candidate;\n  const similarity = typeof best.similarity === 'number' ? best.similarity : -1;\n  const pass = similarity >= (ctx.threshold ?? 0.88);\n  return { json: { candidate, matched: best.phrase, similarity, pass } };\n});\n\nreturn out;"
      },
      "id": "a3c2ba80-bc00-4104-ba6d-a2246469c10a",
      "name": "Code: threshold_flag",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2096,
        288
      ],
      "notes": "Compares nearest match similarity with the threshold and marks pass/fail."
    },
    {
      "parameters": {
        "jsCode": "// === Code: collect_non_matches ===\n// INPUT:  { candidate, matched, similarity, pass }\n// OUTPUT: single item: { non_matches: string[], meta: {...} }\n// PURPOSE: Keep only candidates that did NOT pass threshold (i.e., non-matches)\n\nconst ctx = $('Code: normalize_and_ngrams').first().json; // for threshold & counts\n\nconst failed = $input.all()\n  .map(i => i.json)\n  .filter(j => !j.pass);\n\nreturn [{\n  json: {\n    non_matches: failed.map(x => x.candidate),\n    meta: {\n      threshold: ctx.threshold,\n      candidates_total: ctx.candidates.length,\n      checked_ngrams: '1..'+ctx.MAX_N\n    }\n  }\n}];"
      },
      "id": "df23d155-8ade-4e50-bed6-d443ac38ec6d",
      "name": "Code: collect_non_matches",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2352,
        288
      ],
      "notes": "Produces the final response for the Webhook: list of n-grams that have no strong match."
    },
    {
      "parameters": {
        "inputSource": "passthrough"
      },
      "type": "n8n-nodes-base.executeWorkflowTrigger",
      "typeVersion": 1.1,
      "position": [
        480,
        112
      ],
      "id": "78fbec3f-a58b-43d1-8782-619ee66bb9cc",
      "name": "When Executed by Another Workflow"
    },
    {
      "parameters": {
        "content": "Input: args.phrase - to analyse, company_id,threshold\n"
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        448,
        -128
      ],
      "id": "4caac3ea-29c4-4db2-b267-3fee1fbeff1f",
      "name": "Sticky Note"
    }
  ],
  "connections": {
    "Code: normalize_and_ngrams": {
      "main": [
        [
          {
            "node": "Code: explode_candidates",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Code: explode_candidates": {
      "main": [
        [
          {
            "node": "HTTP: OpenAI Embeddings",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "HTTP: OpenAI Embeddings": {
      "main": [
        [
          {
            "node": "Code: build_vector_literal",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Code: build_vector_literal": {
      "main": [
        [
          {
            "node": "Postgres: vector search",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Postgres: vector search": {
      "main": [
        [
          {
            "node": "Code: threshold_flag",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Code: threshold_flag": {
      "main": [
        [
          {
            "node": "Code: collect_non_matches",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "When Executed by Another Workflow": {
      "main": [
        [
          {
            "node": "Code: normalize_and_ngrams",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {
    "executionOrder": "v1",
    "saveDataSuccessExecution": "none",
    "callerPolicy": "workflowsFromSameOwner"
  },
  "staticData": null,
  "meta": {
    "templateCredsSetupCompleted": true
  },
  "pinData": {
    "When Executed by Another Workflow": [
      {
        "json": {
          "response_id": "resp_68d8d50bac7c8197be5e7cdc8c1c90b8056a29ca24c304f9",
          "call_id": "call_uxM0v9lrgoN4bd7Ti1r65BdW",
          "name": "get_non_matching_ngrams",
          "args": {
            "phrase": "55 школа саратов",
            "company_id": "1",
            "threshold": "0.8"
          },
          "out_index": 1
        }
      }
    ]
  },
  "versionId": "744042bc-c9b5-4c90-b2b6-152927069de8",
  "triggerCount": 1,
  "shared": [
    {
      "createdAt": "2025-09-01T13:14:53.645Z",
      "updatedAt": "2025-09-01T13:14:53.645Z",
      "role": "workflow:owner",
      "workflowId": "bhBscYglbFhVyIcL",
      "projectId": "spKmbJLU4mvACXIB"
    }
  ],
  "tags": [
    {
      "createdAt": "2025-10-07T08:31:00.329Z",
      "updatedAt": "2025-10-07T08:31:00.329Z",
      "id": "mr0GomgPqPG1HJmt",
      "name": "core management"
    }
  ]
}